TOKENIZER:
  MIN_LEN: 2
  BACKEND: "simple"  # options: "simple", "spacy"
  LOWERCASE: true
  ASCII_FOLD: true
  REMOVE_STOPWORDS: true
  STEM: false
  NUMBER_NORMALIZE: true
  SPACY_MODEL: "blank"
  SPACY_DISABLE: null
  NUM_WORKERS: 1 # set to 0 to use os.cpu_count()
  SCAN_COUNT: 100000
  FLUSH_EVERY: 1000
  STORE_POSITIONS: false
  STORE_TOKENS: false

REDIS_HOST: "localhost"
REDIS_PORT: 6379
DOCUMENTS: "msmarco-docs.tsv"
REDIS_PROD: 
  HOST: "seenar.cloud.sci.hpi.de"
  PORT: 6379
  USE: false

SEARCH:
  MAX_RESULTS: 10

INGESTION:
  NUM_DOCUMENTS: 10000
  BATCH_SIZE: 1000

PERF_RUNNER:
  MODE: "ingest" # "ingest" or "query"
  DOCUMENTS_PATH: "data/msmarco-docs.tsv"
  BATCH_SIZE: 400
  ITERATIONS: 100
  CLEANUP: true
  QUERIES_PATH: "queries/sample_queries.txt"

QUERY:
  MAX_PHRASE_LEN: 5

STORAGE:
  TYPE: "disk"  # options: "redis", "filesystem", "disk"
  CURSOR_SIZE: 10
  PATH_DOCS: "data/storage_docs.json"
  PATH_TOKENS: "data/storage_tokens.json"
  KEEP_DOCUMENTS: false
  LOAD_DOCUMENTS: true

# Disk-based index settings (for TYPE: "disk")
DISK_INDEX:
  PATH: "index/"  # Directory where index files are stored
  MEMORY_LIMIT_MB: 900  # Max RAM during indexing (stay under ~950MB to leave headroom)
  DOC_LIMIT: 10000  # Set to a number to limit docs, null for all
  NUM_WORKERS: null  # null = use all CPU cores  
  BATCH_SIZE: 5000  # Docs per batch for parallel tokenization (larger = more efficient)

